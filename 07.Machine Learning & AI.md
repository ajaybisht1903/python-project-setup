# ðŸ¤– Machine Learning & AI

## `TensorFlow`
**Purpose:** The `TensorFlow` library is an open-source platform for machine learning and deep learning. It provides a comprehensive ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML-powered applications.

**Example:**
```python deep_learning.py
import tensorflow as tf
from tensorflow.keras import layers

# Define a simple neural network model
class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = layers.Dense(64, activation='relu')
        self.dense2 = layers.Dense(10)

    def call(self, inputs):
        x = self.dense1(inputs)
        return self.dense2(x)

# Instantiate the model
model = MyModel()

# Print the model's architecture
model.build(input_shape=(None, 784))
model.summary()
```

## `PyTorch`
**Purpose:** The `PyTorch` library is an open-source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. It is known for its dynamic computation graph and strong GPU acceleration.

**Example:**
```python neural_networks.py
import torch
import torch.nn as nn
import torch.optim as optim

# Define a simple neural network
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Instantiate the model
model = SimpleNN()

# Define a loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Print the model's architecture
print(model)
```

## `Keras`
**Purpose:** The `Keras` library is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It is designed to enable fast experimentation with deep neural networks.

**Example:**
```python high_level_api.py
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define a simple neural network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')
])

# Print the model's architecture
model.summary()
```

## `XGBoost`
**Purpose:** The `XGBoost` library is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable. It implements machine learning algorithms under the Gradient Boosting framework.

**Example:**
```python gradient_boosting.py
import xgboost as xgb

# Sample data
data = xgb.DMatrix([[1, 2], [3, 4], [5, 6]], label=[0, 1, 0])

# Define parameters
param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}

# Train the model
bst = xgb.train(param, data)

# Make predictions
preds = bst.predict(data)
print(preds)
```

## `LightGBM`
**Purpose:** The `LightGBM` library is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be distributed and efficient, with a focus on handling large-scale data.

**Example:**
```python fast_boosting.py
import lightgbm as lgb

# Sample data
data = lgb.Dataset([[1, 2], [3, 4], [5, 6]], label=[0, 1, 0])

# Define parameters
param = {'max_depth': 2, 'learning_rate': 1, 'objective': 'binary'}

# Train the model
bst = lgb.train(param, data)

# Make predictions
preds = bst.predict([[1, 2], [3, 4]])
print(preds)
```

These libraries are essential for machine learning and AI in Python, offering a wide range of tools for deep learning, neural networks, and gradient boosting.